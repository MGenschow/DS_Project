{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling urban heat intensity (UHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust paths\n",
    "home_directory = os.path.expanduser( '~' )\n",
    "os.chdir(home_directory + '/DS_Project/modules')\n",
    "config_path = 'config.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn models\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = config['data']['dwd'] + '/uhi_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some randomly generated data\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 1000\n",
    "true_coefficients = np.array([2, -1, 0.5])\n",
    "p = len(true_coefficients)\n",
    "\n",
    "X = np.random.randn(n, p)\n",
    "Y = np.dot(X, true_coefficients) + np.random.randn(n)\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features and target\n",
    "grid_size_meters = 1000\n",
    "with open(path + 'uhi_features_grid' + grid_size_meters + '.pkl', 'rb') as file:\n",
    "    features = pickle.load(file)\n",
    "with open(path + 'uhi_target_grid' + grid_size_meters + '.pkl', 'rb') as file:\n",
    "    targets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring features and targets into right format\n",
    "X = features.drop('target_variable', axis=1).values\n",
    "Y = targets['LST'].values\n",
    "Y = Y.reshape(-1, 1)\n",
    "assert len(X) == len(Y), \"X and Y must have the same length.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also create polynomials\n",
    "poly_2 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "X_poly_2 = poly_2.fit_transform(X)\n",
    "X_poly_3 = poly_3.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to test with their respective hyperparameter grids\n",
    "models = {\n",
    "    'Linear Regression': (LinearRegression(), {}),\n",
    "    'Linear Regression 2nd degree poly': (LinearRegression(), {}),\n",
    "    'Linear Regression 3rd degree poly': (LinearRegression(), {}),\n",
    "    'Decision Tree': (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10]}),\n",
    "    'Random Forest': (RandomForestRegressor(), {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10]}),\n",
    "    'Support Vector Machine': (SVR(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}),\n",
    "    'Neural Network': (MLPRegressor(max_iter=1000), {'hidden_layer_sizes': [(100,), (50, 50)], 'alpha': [0.0001, 0.001], 'activation': ['relu', 'tanh']}),\n",
    "    'XGBoost': (XGBRegressor(max_iter=1000), {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.1, 0.01, 0.001]}),\n",
    "    'ElasticNet': (ElasticNet(), {'alpha': [0.1, 1, 10], 'l1_ratio': [0.2, 0.5, 0.8]}),\n",
    "    'AdaBoost': (AdaBoostRegressor(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measures = {\n",
    "    'Mean Squared Error': make_scorer(mean_squared_error),\n",
    "    'Mean Absolute Error': make_scorer(mean_absolute_error),\n",
    "    'R-squared': make_scorer(r2_score),\n",
    "    'Explained Variance Score': make_scorer(explained_variance_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation with hyperparameter tuning and calculate performance measures\n",
    "pattern = r\"Linear Regression \\d+nd degree poly\"\n",
    "performance_results = {}\n",
    "num_folds = 5\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=kf)\n",
    "    if model_name == 'Linear Regression 2nd degree poly':\n",
    "        grid_search.fit(X_poly_2, Y)\n",
    "    elif model_name == 'Linear Regression 3rd degree poly':\n",
    "        grid_search.fit(X_poly_3, Y)\n",
    "    else:\n",
    "        grid_search.fit(X, Y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    performance_scores = {}\n",
    "    for measure_name, measure_func in performance_measures.items():\n",
    "        # scores = cross_val_score(best_model, X, Y, cv=kf, scoring=measure_func)\n",
    "        scores = cross_val_score(best_model, X, Y, cv=kf, scoring=measure_func, error_score='raise')\n",
    "        mean_score = np.mean(scores)\n",
    "        performance_scores[measure_name] = mean_score\n",
    "    performance_results[model_name] = performance_scores\n",
    "    for measure_name, score in performance_scores.items():\n",
    "        print(f\"{measure_name}: {score:.4f}\")\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame.from_dict(performance_results)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(performance_results, performance_measure):\n",
    "    best_model = None\n",
    "    best_score = None\n",
    "\n",
    "    for model_name, scores in performance_results.items():\n",
    "        score = scores[performance_measure]\n",
    "\n",
    "        if best_score is None:\n",
    "            best_model = model_name\n",
    "            best_score = score\n",
    "        else:\n",
    "            if (\n",
    "                (performance_measure == 'Mean Squared Error' or performance_measure == 'Mean Absolute Error')\n",
    "                and score < best_score\n",
    "            ):\n",
    "                best_model = model_name\n",
    "                best_score = score\n",
    "            elif (\n",
    "                (performance_measure == 'R-squared' or performance_measure == 'Explained Variance Score')\n",
    "                and score > best_score\n",
    "            ):\n",
    "                best_model = model_name\n",
    "                best_score = score\n",
    "\n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_measure = 'Mean Squared Error'\n",
    "best_model_name, best_score = find_best_model(performance_results, best_measure)\n",
    "best_model = models[best_model_name][0]\n",
    "print(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = [[2.0, 3.0, 4.0]]\n",
    "best_model.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'uhi_model_' + grid_size_meters + '.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31e0d8b7548c35cddbff061e0be1eda61b251161626f7fdb4db5aea046cf03e4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('DS_Project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
