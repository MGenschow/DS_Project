{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Torch Imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "# Image utils imports\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file and get potsdam data path\n",
    "import yaml\n",
    "config_path = '/home/tu/tu_tu/tu_zxmav84/DS_Project/modules/config.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "orthophoto_dir = config['data']['orthophotos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths():\n",
    "    \"\"\"\n",
    "    Retrieves the file paths of image and mask files in the 'Patched' directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the file paths of image and mask files.\n",
    "              The dictionary is integer-indexed for easy sampling using an integer index.\n",
    "              The keys are integers representing the index, and the values are tuples\n",
    "              containing the image file path and the corresponding mask file path.\n",
    "\n",
    "    \"\"\"\n",
    "    mask_files = glob(orthophoto_dir + '/labeling_subset/final_masks/*.tif')\n",
    "    image_files = glob(orthophoto_dir + '/labeling_subset/images/*.tif')\n",
    "\n",
    "    print(f\"Indexing files in orthophotos/labeling_subset... \\nFound: \\t {len(image_files)} Images \\n\\t {len(mask_files)} Mask\")\n",
    "\n",
    "    # Get base name of all files and create dict with image and mask file paths\n",
    "    pattern = '\\d+_+\\d+_patch_\\d{1,2}_\\d{1,2}'\n",
    "    patch_base_names = [re.search(pattern, mask_files[i]).group(0) for i in range(len(mask_files))]\n",
    "    # The dictionary is integer-indexed to allow the dataset __getitem__ class to sample using an integer idx\n",
    "    path = orthophoto_dir + '/labeling_subset'\n",
    "    file_paths = {i:(path+'/images/'+name+'.tif',path+'/final_masks/'+name+'.tif') for i, name in enumerate(patch_base_names)}\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(file_paths:dict, test_size:float=0.2):\n",
    "    \"\"\"\n",
    "    Splits a dictionary of file paths into training and test sets.\n",
    "\n",
    "    Args:\n",
    "        file_paths (dict): A dictionary containing the file paths of image and mask files.\n",
    "                           The keys are integers representing the index, and the values are tuples\n",
    "                           containing the image file path and the corresponding mask file path.\n",
    "        test_size (float, optional): The proportion of the dataset to include in the test set.\n",
    "                                     Default is 0.2 (20% of the dataset).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries representing the training and test sets.\n",
    "               Each dictionary is integer-indexed for easy sampling using an integer index.\n",
    "               The keys are integers representing the index, and the values are tuples\n",
    "               containing the image file path and the corresponding mask file path.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train_keys, test_keys = train_test_split(list(file_paths.keys()), test_size=test_size)\n",
    "    train_dict = {i:file_paths[key] for i,key in enumerate(train_keys)}\n",
    "    test_dict = {i:file_paths[key] for i,key in enumerate(test_keys)}\n",
    "    print(f\"Length of all files: {len(file_paths)}\")\n",
    "    print(f\"Length of train ({len(train_dict)}) and test ({len(test_dict)}): {len(train_dict)+len(test_dict)}\")\n",
    "    return train_dict, test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MunichTuningDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.file_paths[idx][0]\n",
    "        mask_filepath = self.file_paths[idx][1]\n",
    "\n",
    "        image = np.array(Image.open(image_filepath))\n",
    "        label_mask = np.array(Image.open(mask_filepath))\n",
    "        # Convert RGB mask to label mask\n",
    "    \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=label_mask)\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_label_mask = transformed['mask']\n",
    "            return transformed_image, transformed_label_mask\n",
    "        else:\n",
    "            return image, label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms to be used in the Training\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=512, width=512),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ColorJitter(p=0.25),\n",
    "        #A.RandomCrop(500, 500),\n",
    "        A.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=512, width=512),\n",
    "        A.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_munich_tuning_loaders(batch_size=2):\n",
    "    file_paths = get_file_paths()\n",
    "    train_dict, test_dict = train_test_split(file_paths, test_size=0.2)\n",
    "    BATCH_SIZE = 2\n",
    "    train_loader = DataLoader(MunichTuningDataset(train_dict, transform=None), \n",
    "                            batch_size = BATCH_SIZE, \n",
    "                            num_workers = 2)\n",
    "    test_loader = DataLoader(MunichTuningDataset(test_dict, transform=test_transform),\n",
    "                            batch_size = BATCH_SIZE, \n",
    "                            num_workers = 2)\n",
    "    print(f\"Length of train loader: {len(train_loader)}; Length of test loader: {len(test_loader)} with batch size {BATCH_SIZE}\")\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing files in orthophotos/labeling_subset... \n",
      "Found: \t 150 Images \n",
      "\t 83 Mask\n",
      "Length of all files: 83\n",
      "Length of train (66) and test (17): 83\n",
      "Length of train loader: 33; Length of test loader: 9 with batch size 2\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_munich_tuning_loaders(batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DataLoader Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_classes = [\n",
    "       (0, 0, 0), # ignore\n",
    "       (255, 255, 225), # impervious\n",
    "       (255,  0, 255), # building\n",
    "       (255, 200, 0), # low vegetation\n",
    "       (0,  0,  255), # water\n",
    "       (0, 130, 0)] # trees\n",
    "Label_classes = [\n",
    "       \"ignore\",\n",
    "       \"impervious\",\n",
    "       \"building\",\n",
    "       \"low vegetation\",\n",
    "       \"water\",\n",
    "       \"trees\"]\n",
    "\n",
    "idx2label = {key: value for key, value in enumerate(Label_classes)}\n",
    "\n",
    "# Create a dictionary to translate a mask to a rgb tensor\n",
    "idx2rgb = {key: value for key, value in enumerate(RGB_classes)}\n",
    "rgb2idx = {v: k for k, v in idx2rgb.items()}\n",
    "\n",
    "# Dict to map from label to rgb\n",
    "rgb2label = dict(zip(Label_classes, RGB_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# iterate over the train_loader\n",
    "for i, (images, masks) in enumerate(train_loader):\n",
    "    # stop after the first batch\n",
    "    #if i > 1:\n",
    "    #    break\n",
    "\n",
    "    batch_size = images.shape[0]\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        # select the j-th image and mask from the batch\n",
    "        image = images[j].numpy()\n",
    "        mask = masks[j].numpy()\n",
    "\n",
    "        # PyTorch dataloaders usually return images in (C, H, W) format,\n",
    "        # so we need to transpose this to (H, W, C) for matplotlib to display it correctly\n",
    "        if image.shape[0] == 3:\n",
    "            image = image.transpose((1, 2, 0))\n",
    "\n",
    "        # Create an empty RGB mask\n",
    "        mask_rgb = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "        # Map each label index to its RGB equivalent\n",
    "        for idx, rgb in idx2rgb.items():\n",
    "            mask_rgb[mask == idx] = rgb\n",
    "        \n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        ax[0].imshow(image)  # display the image\n",
    "        ax[0].set_title(f'Image {j+1}')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(mask_rgb)  # display the mask\n",
    "        ax[1].set_title(f'Label Mask {j+1}')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        # Create a list of patches for the legend\n",
    "        patches = [mpatches.Patch(color=np.array(rgb)/255., label=label) for label, rgb in rgb2label.items()]\n",
    "\n",
    "        # Create legend\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Classes\")\n",
    "\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31e0d8b7548c35cddbff061e0be1eda61b251161626f7fdb4db5aea046cf03e4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('DS_Project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
